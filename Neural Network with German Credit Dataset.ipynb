{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7949ac42-6dc7-4bfc-a13b-5197233524f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'kredit': [1 0]\n",
      "\n",
      "Feedforward Neural Network Performance on German Credit:\n",
      "Accuracy : 0.6933\n",
      "Precision: 0.7757\n",
      "Recall   : 0.7905\n",
      "F1 Score : 0.7830\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Arhamsoft\\Desktop\\Talha Talib Thesis\\german_credit_data.csv\")\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Show target values\n",
    "print(\"Unique values in 'kredit':\", df['kredit'].unique())\n",
    "\n",
    "# Target and features\n",
    "y = df['kredit']\n",
    "X = df.drop(columns=['kredit'])\n",
    "\n",
    "# Encode categorical features\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Dataloader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# FFNN Definition\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Initialize\n",
    "model = FFNN(input_dim=X_train.shape[1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_tensor)\n",
    "    y_pred = torch.argmax(logits, axis=1).numpy()\n",
    "\n",
    "# Performance metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nFeedforward Neural Network Performance on German Credit:\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbca6f84-fb17-446f-b8de-5e1e33dc7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reweighed FFNN Performance (German Credit):\n",
      "Accuracy : 0.7000\n",
      "Precision: 0.7808\n",
      "Recall   : 0.8028\n",
      "F1 Score : 0.7917\n",
      "\n",
      "Fairness Metrics (Reweighing):\n",
      "Statistical Parity Difference : 0.1080\n",
      "Equal Opportunity Difference : 0.3321\n",
      "Disparate Impact Ratio       : 1.1501\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame, \n",
    "    demographic_parity_difference, \n",
    "    equalized_odds_difference, \n",
    "    selection_rate\n",
    ")\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "# Load and clean dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Arhamsoft\\Desktop\\Talha Talib Thesis\\german_credit_data.csv\")\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define protected attribute\n",
    "df['sex_binary'] = df['famges'].apply(lambda x: 0 if x == 4 else 1)\n",
    "\n",
    "# Target and protected\n",
    "y = df[\"kredit\"]\n",
    "protected = df[\"sex_binary\"]\n",
    "\n",
    "# Prepare features (exclude target and protected)\n",
    "X = df.drop(columns=[\"kredit\", \"sex_binary\"])\n",
    "\n",
    "# Encode categorical features\n",
    "X_encoded = X.copy()\n",
    "for col in X_encoded.select_dtypes(include=\"object\").columns:\n",
    "    X_encoded[col] = LabelEncoder().fit_transform(X_encoded[col])\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "X_df = pd.DataFrame(X_scaled, columns=X_encoded.columns)\n",
    "\n",
    "# Final combined DataFrame for AIF360\n",
    "df_ffnn = pd.concat([\n",
    "    X_df.reset_index(drop=True),\n",
    "    y.reset_index(drop=True).rename(\"target\"),\n",
    "    protected.reset_index(drop=True).rename(\"sex_binary\")\n",
    "], axis=1)\n",
    "\n",
    "# BinaryLabelDataset\n",
    "bld = BinaryLabelDataset(\n",
    "    df=df_ffnn,\n",
    "    label_names=[\"target\"],\n",
    "    protected_attribute_names=[\"sex_binary\"],\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0\n",
    ")\n",
    "\n",
    "# Split into train/test\n",
    "train_bld, test_bld = bld.split([0.7], shuffle=True)\n",
    "\n",
    "# Apply Reweighing\n",
    "rw = Reweighing(privileged_groups=[{\"sex_binary\": 1}], unprivileged_groups=[{\"sex_binary\": 0}])\n",
    "train_rw = rw.fit_transform(train_bld)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_rw = torch.tensor(train_rw.features, dtype=torch.float32)\n",
    "y_train_rw = torch.tensor(train_rw.labels.ravel(), dtype=torch.long)\n",
    "sample_weights = torch.tensor(train_rw.instance_weights, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_rw, y_train_rw, sample_weights)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# FFNN\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Initialize model\n",
    "model = FFNN(input_dim=X_train_rw.shape[1])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    for xb, yb, wb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        (loss * wb).mean().backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "X_test_tensor = torch.tensor(test_bld.features, dtype=torch.float32)\n",
    "y_test_array = test_bld.labels.ravel()\n",
    "\n",
    "# Get protected attribute from test set\n",
    "test_df, _ = test_bld.convert_to_dataframe()\n",
    "prot_test_array = test_df[\"sex_binary\"].values.astype(int)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_tensor)\n",
    "    y_pred = torch.argmax(logits, axis=1).numpy()\n",
    "\n",
    "# Performance metrics\n",
    "acc = accuracy_score(y_test_array, y_pred)\n",
    "prec = precision_score(y_test_array, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test_array, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_array, y_pred, zero_division=0)\n",
    "\n",
    "print(\"Reweighed FFNN Performance (German Credit):\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# Fairness metrics\n",
    "fair_metrics = MetricFrame(\n",
    "    metrics={\n",
    "        \"accuracy\": accuracy_score,\n",
    "        \"precision\": precision_score,\n",
    "        \"recall\": recall_score,\n",
    "        \"f1\": f1_score,\n",
    "        \"selection_rate\": selection_rate\n",
    "    },\n",
    "    y_true=y_test_array,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=prot_test_array\n",
    ")\n",
    "\n",
    "spd = demographic_parity_difference(y_test_array, y_pred, sensitive_features=prot_test_array)\n",
    "eod = equalized_odds_difference(y_test_array, y_pred, sensitive_features=prot_test_array)\n",
    "di_ratio = fair_metrics.by_group['selection_rate'].max() / fair_metrics.by_group['selection_rate'].min()\n",
    "\n",
    "print(\"\\nFairness Metrics (Reweighing):\")\n",
    "print(f\"Statistical Parity Difference : {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference : {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio       : {di_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d90c2f9-b47b-4d8b-b7c3-54089a52763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\AppData\\Local\\Temp\\ipykernel_10612\\4260327958.py:14: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\AppData\\Local\\Temp\\ipykernel_10612\\4260327958.py:14: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:164: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:164: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.758644; batch adversarial loss: 1.068746\n",
      "epoch 1; iter: 0; batch classifier loss: 0.684667; batch adversarial loss: 1.132181\n",
      "epoch 2; iter: 0; batch classifier loss: 0.615493; batch adversarial loss: 1.206151\n",
      "epoch 3; iter: 0; batch classifier loss: 0.629196; batch adversarial loss: 1.143985\n",
      "epoch 4; iter: 0; batch classifier loss: 0.574645; batch adversarial loss: 1.276730\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549190; batch adversarial loss: 1.218072\n",
      "epoch 6; iter: 0; batch classifier loss: 0.504350; batch adversarial loss: 1.240169\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501920; batch adversarial loss: 1.299249\n",
      "epoch 8; iter: 0; batch classifier loss: 0.517070; batch adversarial loss: 1.300938\n",
      "epoch 9; iter: 0; batch classifier loss: 0.442040; batch adversarial loss: 1.374599\n",
      "epoch 10; iter: 0; batch classifier loss: 0.471912; batch adversarial loss: 1.397811\n",
      "epoch 11; iter: 0; batch classifier loss: 0.483163; batch adversarial loss: 1.274483\n",
      "epoch 12; iter: 0; batch classifier loss: 0.450226; batch adversarial loss: 1.370833\n",
      "epoch 13; iter: 0; batch classifier loss: 0.489520; batch adversarial loss: 1.244694\n",
      "epoch 14; iter: 0; batch classifier loss: 0.441582; batch adversarial loss: 1.264434\n",
      "epoch 15; iter: 0; batch classifier loss: 0.434410; batch adversarial loss: 1.328271\n",
      "epoch 16; iter: 0; batch classifier loss: 0.437415; batch adversarial loss: 1.344990\n",
      "epoch 17; iter: 0; batch classifier loss: 0.428250; batch adversarial loss: 1.364837\n",
      "epoch 18; iter: 0; batch classifier loss: 0.455900; batch adversarial loss: 1.339742\n",
      "epoch 19; iter: 0; batch classifier loss: 0.423997; batch adversarial loss: 1.305037\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480994; batch adversarial loss: 1.270671\n",
      "epoch 21; iter: 0; batch classifier loss: 0.391170; batch adversarial loss: 1.328571\n",
      "epoch 22; iter: 0; batch classifier loss: 0.399786; batch adversarial loss: 1.173036\n",
      "epoch 23; iter: 0; batch classifier loss: 0.414817; batch adversarial loss: 1.233009\n",
      "epoch 24; iter: 0; batch classifier loss: 0.408739; batch adversarial loss: 1.282524\n",
      "epoch 25; iter: 0; batch classifier loss: 0.456803; batch adversarial loss: 1.197985\n",
      "epoch 26; iter: 0; batch classifier loss: 0.434312; batch adversarial loss: 1.271446\n",
      "epoch 27; iter: 0; batch classifier loss: 0.456710; batch adversarial loss: 1.238969\n",
      "epoch 28; iter: 0; batch classifier loss: 0.431514; batch adversarial loss: 1.208838\n",
      "epoch 29; iter: 0; batch classifier loss: 0.296596; batch adversarial loss: 1.307435\n",
      "epoch 30; iter: 0; batch classifier loss: 0.491841; batch adversarial loss: 1.163290\n",
      "epoch 31; iter: 0; batch classifier loss: 0.332953; batch adversarial loss: 1.239470\n",
      "epoch 32; iter: 0; batch classifier loss: 0.389836; batch adversarial loss: 1.181334\n",
      "epoch 33; iter: 0; batch classifier loss: 0.405911; batch adversarial loss: 1.149065\n",
      "epoch 34; iter: 0; batch classifier loss: 0.417031; batch adversarial loss: 1.212041\n",
      "epoch 35; iter: 0; batch classifier loss: 0.367489; batch adversarial loss: 1.147781\n",
      "epoch 36; iter: 0; batch classifier loss: 0.405180; batch adversarial loss: 1.124985\n",
      "epoch 37; iter: 0; batch classifier loss: 0.363691; batch adversarial loss: 1.193614\n",
      "epoch 38; iter: 0; batch classifier loss: 0.385626; batch adversarial loss: 1.145517\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445373; batch adversarial loss: 1.130845\n",
      "epoch 40; iter: 0; batch classifier loss: 0.366022; batch adversarial loss: 1.117010\n",
      "epoch 41; iter: 0; batch classifier loss: 0.385883; batch adversarial loss: 1.063864\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409546; batch adversarial loss: 1.098661\n",
      "epoch 43; iter: 0; batch classifier loss: 0.406984; batch adversarial loss: 1.128254\n",
      "epoch 44; iter: 0; batch classifier loss: 0.352521; batch adversarial loss: 1.057224\n",
      "epoch 45; iter: 0; batch classifier loss: 0.400164; batch adversarial loss: 1.055649\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451223; batch adversarial loss: 1.057715\n",
      "epoch 47; iter: 0; batch classifier loss: 0.371638; batch adversarial loss: 1.087121\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412888; batch adversarial loss: 1.000630\n",
      "epoch 49; iter: 0; batch classifier loss: 0.296212; batch adversarial loss: 1.073076\n",
      "Adversarial Debiasing (FFNN) Performance on German Credit:\n",
      "Accuracy : 0.7567\n",
      "Precision: 0.7930\n",
      "Recall   : 0.8738\n",
      "F1 Score : 0.8314\n",
      "\n",
      "Fairness Metrics (Adversarial Debiasing):\n",
      "Statistical Parity Difference : 0.2243\n",
      "Equal Opportunity Difference : 0.5465\n",
      "Disparate Impact Ratio       : 1.3043\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    demographic_parity_difference,\n",
    "    equalized_odds_difference,\n",
    "    selection_rate\n",
    ")\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Load and preprocess\n",
    "# ----------------------------\n",
    "df = pd.read_csv(r\"C:\\Users\\Arhamsoft\\Desktop\\Talha Talib Thesis\\german_credit_data.csv\")\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Binary protected attribute: 1 = male, 0 = female\n",
    "df[\"sex_binary\"] = df[\"famges\"].apply(lambda x: 0 if x == 4 else 1)\n",
    "\n",
    "# Define target and features\n",
    "y = df[\"kredit\"]\n",
    "protected = df[\"sex_binary\"]\n",
    "X = df.drop(columns=[\"kredit\", \"sex_binary\"])  # exclude target and protected\n",
    "\n",
    "# Encode categorical features\n",
    "X_encoded = X.copy()\n",
    "for col in X_encoded.select_dtypes(include=\"object\").columns:\n",
    "    X_encoded[col] = LabelEncoder().fit_transform(X_encoded[col])\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "X_df = pd.DataFrame(X_scaled, columns=X_encoded.columns)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Create BinaryLabelDataset and Split\n",
    "# ----------------------------\n",
    "bld_df = pd.concat([\n",
    "    X_df.reset_index(drop=True),\n",
    "    y.reset_index(drop=True).rename(\"target\"),\n",
    "    protected.reset_index(drop=True).rename(\"sex_binary\")\n",
    "], axis=1)\n",
    "\n",
    "dataset = BinaryLabelDataset(\n",
    "    df=bld_df,\n",
    "    label_names=[\"target\"],\n",
    "    protected_attribute_names=[\"sex_binary\"],\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0\n",
    ")\n",
    "\n",
    "train_dataset, test_dataset = dataset.split([0.7], shuffle=True)\n",
    "\n",
    "# ----------------------------------\n",
    "# Step 3: Train Adversarial Debiasing\n",
    "# ----------------------------------\n",
    "sess = tf.Session()\n",
    "ad_model = AdversarialDebiasing(\n",
    "    privileged_groups=[{\"sex_binary\": 1}],\n",
    "    unprivileged_groups=[{\"sex_binary\": 0}],\n",
    "    scope_name='adv_debiasing_ffnn',\n",
    "    sess=sess,\n",
    "    debias=True,\n",
    "    num_epochs=50,\n",
    "    batch_size=128\n",
    ")\n",
    "ad_model.fit(train_dataset)\n",
    "\n",
    "# ----------------------------------\n",
    "# Step 4: Predictions and Performance\n",
    "# ----------------------------------\n",
    "pred_dataset = ad_model.predict(test_dataset)\n",
    "\n",
    "y_true = test_dataset.labels.ravel()\n",
    "y_pred = pred_dataset.labels.ravel()\n",
    "protected_test = test_dataset.protected_attributes.ravel()\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "print(\"Adversarial Debiasing (FFNN) Performance on German Credit:\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Step 5: Fairness Metrics\n",
    "# ----------------------------------\n",
    "# Ensure lengths match before MetricFrame\n",
    "assert len(y_true) == len(protected_test), \"Mismatch in y_true and sensitive_features lengths\"\n",
    "\n",
    "fair_metrics = MetricFrame(\n",
    "    metrics={\n",
    "        \"accuracy\": accuracy_score,\n",
    "        \"precision\": precision_score,\n",
    "        \"recall\": recall_score,\n",
    "        \"f1\": f1_score,\n",
    "        \"selection_rate\": selection_rate\n",
    "    },\n",
    "    y_true=y_true,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=protected_test\n",
    ")\n",
    "\n",
    "spd = demographic_parity_difference(y_true, y_pred, sensitive_features=protected_test)\n",
    "eod = equalized_odds_difference(y_true, y_pred, sensitive_features=protected_test)\n",
    "\n",
    "# Handle zero-division in Disparate Impact Ratio\n",
    "sr = fair_metrics.by_group['selection_rate']\n",
    "di_ratio = sr.max() / sr.min() if sr.min() > 0 else np.inf\n",
    "\n",
    "print(\"\\nFairness Metrics (Adversarial Debiasing):\")\n",
    "print(f\"Statistical Parity Difference : {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference : {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio       : {di_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ff80a1-aaac-48e9-b524-237d11a71bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equalized Odds Postprocessing Performance on German Credit:\n",
      "Accuracy : 0.3633\n",
      "Precision: 0.7586\n",
      "Recall   : 0.1068\n",
      "F1 Score : 0.1872\n",
      "\n",
      "Fairness Metrics (Equalized Odds Postprocessing):\n",
      "Statistical Parity Difference : 0.0205\n",
      "Equal Opportunity Difference : 0.0814\n",
      "Disparate Impact Ratio       : 1.2160\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame, \n",
    "    demographic_parity_difference, \n",
    "    equalized_odds_difference, \n",
    "    selection_rate\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 1: Convert predicted FFNN results into dataset\n",
    "# -----------------------------------------------------\n",
    "# Use the same `test_dataset` and `y_pred` and `y_true` from FFNN Adversarial Debiasing output\n",
    "\n",
    "# Create predicted dataset from FFNN output\n",
    "pred_dataset = test_dataset.copy()\n",
    "pred_dataset.labels = y_pred.reshape(-1, 1)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 2: Equalized Odds Postprocessing\n",
    "# -----------------------------------------------------\n",
    "eq_odds = EqOddsPostprocessing(\n",
    "    unprivileged_groups=[{'sex_binary': 0}],\n",
    "    privileged_groups=[{'sex_binary': 1}],\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "eq_odds = eq_odds.fit(test_dataset, pred_dataset)\n",
    "eq_odds_pred = eq_odds.predict(pred_dataset)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 3: Performance Metrics\n",
    "# -----------------------------------------------------\n",
    "y_pred_eq = eq_odds_pred.labels.ravel()\n",
    "protected_test = test_dataset.protected_attributes.ravel()\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred_eq)\n",
    "prec = precision_score(y_true, y_pred_eq)\n",
    "rec = recall_score(y_true, y_pred_eq)\n",
    "f1 = f1_score(y_true, y_pred_eq)\n",
    "\n",
    "print(\"Equalized Odds Postprocessing Performance on German Credit:\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 4: Fairness Metrics\n",
    "# -----------------------------------------------------\n",
    "fair_metrics = MetricFrame(\n",
    "    metrics={\n",
    "        \"accuracy\": accuracy_score,\n",
    "        \"precision\": precision_score,\n",
    "        \"recall\": recall_score,\n",
    "        \"f1\": f1_score,\n",
    "        \"selection_rate\": selection_rate\n",
    "    },\n",
    "    y_true=y_true,\n",
    "    y_pred=y_pred_eq,\n",
    "    sensitive_features=protected_test\n",
    ")\n",
    "\n",
    "spd = demographic_parity_difference(y_true, y_pred_eq, sensitive_features=protected_test)\n",
    "eod = equalized_odds_difference(y_true, y_pred_eq, sensitive_features=protected_test)\n",
    "di_ratio = fair_metrics.by_group['selection_rate'].max() / fair_metrics.by_group['selection_rate'].min()\n",
    "\n",
    "print(\"\\nFairness Metrics (Equalized Odds Postprocessing):\")\n",
    "print(f\"Statistical Parity Difference : {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference : {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio       : {di_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f802b-43f0-46ad-9c97-4969812b17b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-env]",
   "language": "python",
   "name": "conda-env-tf-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
