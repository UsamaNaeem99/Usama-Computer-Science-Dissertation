{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7949ac42-6dc7-4bfc-a13b-5197233524f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arhamsoft\\AppData\\Local\\Temp\\ipykernel_8972\\3099806426.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['DateOfBirth'] = pd.to_datetime(df['DateOfBirth'], errors='coerce')\n",
      "C:\\Users\\Arhamsoft\\AppData\\Local\\Temp\\ipykernel_8972\\3099806426.py:32: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Screening_Date'] = pd.to_datetime(df['Screening_Date'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedforward Neural Network Performance on COMPAS:\n",
      "Accuracy : 0.7992\n",
      "Precision: 0.6790\n",
      "Recall   : 0.8003\n",
      "F1 Score : 0.7346\n",
      "\n",
      "Fairness Metrics (FFNN):\n",
      "Statistical Parity Difference : 0.2699\n",
      "Equal Opportunity Difference : 0.1744\n",
      "Disparate Impact Ratio       : 2.0345\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame, \n",
    "    demographic_parity_difference, \n",
    "    equalized_odds_difference, \n",
    "    selection_rate\n",
    ")\n",
    "\n",
    "# Load and preprocess COMPAS dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Arhamsoft\\Desktop\\Talha Talib Thesis\\compas-scores-raw.csv\")\n",
    "\n",
    "# Filtering\n",
    "df = df[\n",
    "    (df['IsCompleted'] == 1) &\n",
    "    (df['ScoreText'].isin(['Low', 'Medium', 'High']))\n",
    "]\n",
    "df['two_year_recid'] = df['ScoreText'].map({'Low': 0, 'Medium': 1, 'High': 1})\n",
    "df = df[df['Ethnic_Code_Text'].isin(['African-American', 'Caucasian'])]\n",
    "df['race_binary'] = df['Ethnic_Code_Text'].map({'Caucasian': 0, 'African-American': 1})\n",
    "df['sex_binary'] = df['Sex_Code_Text'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "df['DateOfBirth'] = pd.to_datetime(df['DateOfBirth'], errors='coerce')\n",
    "df['Screening_Date'] = pd.to_datetime(df['Screening_Date'], errors='coerce')\n",
    "df['age'] = (df['Screening_Date'] - df['DateOfBirth']).dt.days // 365\n",
    "df = df.dropna(subset=['age', 'LegalStatus', 'CustodyStatus', 'RecSupervisionLevel'])\n",
    "\n",
    "# One-hot encode\n",
    "df = pd.get_dummies(df, columns=['LegalStatus', 'CustodyStatus', 'RecSupervisionLevel'], drop_first=True)\n",
    "\n",
    "# Features and targets\n",
    "features = ['sex_binary', 'age'] + [col for col in df.columns if col.startswith(('LegalStatus_', 'CustodyStatus_', 'RecSupervisionLevel_'))]\n",
    "X = df[features]\n",
    "y = df['two_year_recid']\n",
    "protected = df['race_binary']\n",
    "\n",
    "# Normalize\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test, prot_train, prot_test = train_test_split(\n",
    "    X_scaled, y, protected, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Class weights\n",
    "import numpy as np\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0, 1]), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "# Datasets and DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Define FFNN\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "model = FFNN(input_dim=X_train.shape[1])\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_logits = model(X_test_tensor)\n",
    "    y_pred = torch.argmax(y_logits, axis=1).numpy()\n",
    "\n",
    "# Performance\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(\"Feedforward Neural Network Performance on COMPAS:\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# Fairness Metrics\n",
    "fair_metrics = MetricFrame(\n",
    "    metrics={\n",
    "        \"accuracy\": accuracy_score,\n",
    "        \"precision\": precision_score,\n",
    "        \"recall\": recall_score,\n",
    "        \"f1\": f1_score,\n",
    "        \"selection_rate\": selection_rate\n",
    "    },\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=prot_test\n",
    ")\n",
    "\n",
    "spd = demographic_parity_difference(y_test, y_pred, sensitive_features=prot_test)\n",
    "eod = equalized_odds_difference(y_test, y_pred, sensitive_features=prot_test)\n",
    "di_ratio = fair_metrics.by_group['selection_rate'].max() / fair_metrics.by_group['selection_rate'].min()\n",
    "\n",
    "print(\"\\nFairness Metrics (FFNN):\")\n",
    "print(f\"Statistical Parity Difference : {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference : {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio       : {di_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "400c10c1-d829-47c2-8a9c-9f2bf580cced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reweighed FFNN Performance:\n",
      "Accuracy : 0.8028\n",
      "Precision: 0.7033\n",
      "Recall   : 0.7530\n",
      "F1 Score : 0.7273\n",
      "\n",
      "Fairness Metrics (Reweighing):\n",
      "Statistical Parity Difference : 0.2120\n",
      "Equal Opportunity Difference : 0.1132\n",
      "Disparate Impact Ratio       : 1.8269\n"
     ]
    }
   ],
   "source": [
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    demographic_parity_difference,\n",
    "    equalized_odds_difference,\n",
    "    selection_rate\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare DataFrame for AIF360\n",
    "df_ffnn = pd.concat([X_scaled.reset_index(drop=True), y.reset_index(drop=True), protected.reset_index(drop=True)], axis=1)\n",
    "df_ffnn = df_ffnn.rename(columns={'race_binary': 'race', 'two_year_recid': 'target'})\n",
    "\n",
    "# Create AIF360 BinaryLabelDataset\n",
    "bld = BinaryLabelDataset(\n",
    "    df=df_ffnn,\n",
    "    label_names=[\"target\"],\n",
    "    protected_attribute_names=[\"race\"],\n",
    "    favorable_label=0,\n",
    "    unfavorable_label=1\n",
    ")\n",
    "\n",
    "# Split into train/test\n",
    "train_bld, test_bld = bld.split([0.7], shuffle=True)\n",
    "\n",
    "# Apply Reweighing\n",
    "rw = Reweighing(privileged_groups=[{\"race\": 0}], unprivileged_groups=[{\"race\": 1}])\n",
    "train_rw = rw.fit_transform(train_bld)\n",
    "\n",
    "# Extract weighted training data\n",
    "X_train_rw = torch.tensor(train_rw.features, dtype=torch.float32)\n",
    "y_train_rw = torch.tensor(train_rw.labels.ravel().astype(int), dtype=torch.long)  # ensure labels are 0/1\n",
    "sample_weights = torch.tensor(train_rw.instance_weights, dtype=torch.float32)\n",
    "\n",
    "# DataLoader with instance weights\n",
    "train_dataset_rw = TensorDataset(X_train_rw, y_train_rw, sample_weights)\n",
    "train_loader_rw = DataLoader(train_dataset_rw, batch_size=128, shuffle=True)\n",
    "\n",
    "# Redefine model (make sure architecture matches input size)\n",
    "model_rw = FFNN(input_dim=X_train_rw.shape[1])\n",
    "optimizer = optim.Adam(model_rw.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')  # allow per-instance weighting\n",
    "\n",
    "# Train model with reweighted loss\n",
    "for epoch in range(100):\n",
    "    model_rw.train()\n",
    "    for xb, yb, wb in train_loader_rw:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model_rw(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        weighted_loss = (loss * wb).mean()\n",
    "        weighted_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model_rw.eval()\n",
    "X_test_tensor = torch.tensor(test_bld.features, dtype=torch.float32)\n",
    "y_test_array = test_bld.labels.ravel().astype(int)\n",
    "prot_test_array = test_bld.protected_attributes.ravel().astype(int)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model_rw(X_test_tensor)\n",
    "    y_pred_rw = torch.argmax(logits, axis=1).numpy()\n",
    "\n",
    "# Performance Metrics\n",
    "acc = accuracy_score(y_test_array, y_pred_rw)\n",
    "prec = precision_score(y_test_array, y_pred_rw, zero_division=0)\n",
    "rec = recall_score(y_test_array, y_pred_rw, zero_division=0)\n",
    "f1 = f1_score(y_test_array, y_pred_rw, zero_division=0)\n",
    "\n",
    "print(\"Reweighed FFNN Performance:\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# Fairness Metrics\n",
    "fair_metrics_rw = MetricFrame(\n",
    "    metrics={\n",
    "        \"accuracy\": accuracy_score,\n",
    "        \"precision\": precision_score,\n",
    "        \"recall\": recall_score,\n",
    "        \"f1\": f1_score,\n",
    "        \"selection_rate\": selection_rate\n",
    "    },\n",
    "    y_true=y_test_array,\n",
    "    y_pred=y_pred_rw,\n",
    "    sensitive_features=prot_test_array\n",
    ")\n",
    "\n",
    "spd = demographic_parity_difference(y_test_array, y_pred_rw, sensitive_features=prot_test_array)\n",
    "eod = equalized_odds_difference(y_test_array, y_pred_rw, sensitive_features=prot_test_array)\n",
    "\n",
    "# Prevent division by zero in Disparate Impact Ratio\n",
    "sr_values = fair_metrics_rw.by_group['selection_rate']\n",
    "di_ratio = sr_values.max() / sr_values.min() if sr_values.min() > 0 else float('nan')\n",
    "\n",
    "print(\"\\nFairness Metrics (Reweighing):\")\n",
    "print(f\"Statistical Parity Difference : {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference : {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio       : {di_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8de1cb0-e04c-4a97-83e1-fdb103299cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\AppData\\Local\\Temp\\ipykernel_8972\\2634554276.py:2: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\AppData\\Local\\Temp\\ipykernel_8972\\2634554276.py:2: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:164: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:164: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.698446; batch adversarial loss: 0.707416\n",
      "epoch 0; iter: 200; batch classifier loss: 0.494751; batch adversarial loss: 0.690506\n",
      "epoch 1; iter: 0; batch classifier loss: 0.506592; batch adversarial loss: 0.682501\n",
      "epoch 1; iter: 200; batch classifier loss: 0.449994; batch adversarial loss: 0.668348\n",
      "epoch 2; iter: 0; batch classifier loss: 0.499583; batch adversarial loss: 0.677852\n",
      "epoch 2; iter: 200; batch classifier loss: 0.426547; batch adversarial loss: 0.653829\n",
      "epoch 3; iter: 0; batch classifier loss: 0.459311; batch adversarial loss: 0.681259\n",
      "epoch 3; iter: 200; batch classifier loss: 0.466519; batch adversarial loss: 0.684293\n",
      "epoch 4; iter: 0; batch classifier loss: 0.372865; batch adversarial loss: 0.664264\n",
      "epoch 4; iter: 200; batch classifier loss: 0.447506; batch adversarial loss: 0.676459\n",
      "epoch 5; iter: 0; batch classifier loss: 0.500453; batch adversarial loss: 0.681883\n",
      "epoch 5; iter: 200; batch classifier loss: 0.379989; batch adversarial loss: 0.651813\n",
      "epoch 6; iter: 0; batch classifier loss: 0.455027; batch adversarial loss: 0.619794\n",
      "epoch 6; iter: 200; batch classifier loss: 0.518586; batch adversarial loss: 0.649356\n",
      "epoch 7; iter: 0; batch classifier loss: 0.449908; batch adversarial loss: 0.671512\n",
      "epoch 7; iter: 200; batch classifier loss: 0.404381; batch adversarial loss: 0.659765\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552026; batch adversarial loss: 0.664639\n",
      "epoch 8; iter: 200; batch classifier loss: 0.398386; batch adversarial loss: 0.685319\n",
      "epoch 9; iter: 0; batch classifier loss: 0.437357; batch adversarial loss: 0.663373\n",
      "epoch 9; iter: 200; batch classifier loss: 0.449813; batch adversarial loss: 0.655627\n",
      "epoch 10; iter: 0; batch classifier loss: 0.451842; batch adversarial loss: 0.648428\n",
      "epoch 10; iter: 200; batch classifier loss: 0.431042; batch adversarial loss: 0.658331\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525358; batch adversarial loss: 0.645656\n",
      "epoch 11; iter: 200; batch classifier loss: 0.412497; batch adversarial loss: 0.632647\n",
      "epoch 12; iter: 0; batch classifier loss: 0.427860; batch adversarial loss: 0.665831\n",
      "epoch 12; iter: 200; batch classifier loss: 0.422792; batch adversarial loss: 0.698556\n",
      "epoch 13; iter: 0; batch classifier loss: 0.482086; batch adversarial loss: 0.643384\n",
      "epoch 13; iter: 200; batch classifier loss: 0.494954; batch adversarial loss: 0.677836\n",
      "epoch 14; iter: 0; batch classifier loss: 0.498483; batch adversarial loss: 0.685303\n",
      "epoch 14; iter: 200; batch classifier loss: 0.452147; batch adversarial loss: 0.674651\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500466; batch adversarial loss: 0.678458\n",
      "epoch 15; iter: 200; batch classifier loss: 0.481104; batch adversarial loss: 0.668953\n",
      "epoch 16; iter: 0; batch classifier loss: 0.477148; batch adversarial loss: 0.632386\n",
      "epoch 16; iter: 200; batch classifier loss: 0.493367; batch adversarial loss: 0.642938\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501645; batch adversarial loss: 0.651273\n",
      "epoch 17; iter: 200; batch classifier loss: 0.492151; batch adversarial loss: 0.676802\n",
      "epoch 18; iter: 0; batch classifier loss: 0.360249; batch adversarial loss: 0.693082\n",
      "epoch 18; iter: 200; batch classifier loss: 0.393133; batch adversarial loss: 0.632723\n",
      "epoch 19; iter: 0; batch classifier loss: 0.447345; batch adversarial loss: 0.603681\n",
      "epoch 19; iter: 200; batch classifier loss: 0.486146; batch adversarial loss: 0.687649\n",
      "epoch 20; iter: 0; batch classifier loss: 0.387734; batch adversarial loss: 0.663303\n",
      "epoch 20; iter: 200; batch classifier loss: 0.551836; batch adversarial loss: 0.654360\n",
      "epoch 21; iter: 0; batch classifier loss: 0.413739; batch adversarial loss: 0.655515\n",
      "epoch 21; iter: 200; batch classifier loss: 0.531642; batch adversarial loss: 0.597722\n",
      "epoch 22; iter: 0; batch classifier loss: 0.572016; batch adversarial loss: 0.698623\n",
      "epoch 22; iter: 200; batch classifier loss: 0.354055; batch adversarial loss: 0.639934\n",
      "epoch 23; iter: 0; batch classifier loss: 0.425696; batch adversarial loss: 0.637943\n",
      "epoch 23; iter: 200; batch classifier loss: 0.436351; batch adversarial loss: 0.639778\n",
      "epoch 24; iter: 0; batch classifier loss: 0.495449; batch adversarial loss: 0.638436\n",
      "epoch 24; iter: 200; batch classifier loss: 0.394311; batch adversarial loss: 0.631723\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472235; batch adversarial loss: 0.703052\n",
      "epoch 25; iter: 200; batch classifier loss: 0.371859; batch adversarial loss: 0.691624\n",
      "epoch 26; iter: 0; batch classifier loss: 0.532227; batch adversarial loss: 0.621547\n",
      "epoch 26; iter: 200; batch classifier loss: 0.428325; batch adversarial loss: 0.678137\n",
      "epoch 27; iter: 0; batch classifier loss: 0.491125; batch adversarial loss: 0.631544\n",
      "epoch 27; iter: 200; batch classifier loss: 0.508775; batch adversarial loss: 0.658152\n",
      "epoch 28; iter: 0; batch classifier loss: 0.513378; batch adversarial loss: 0.654891\n",
      "epoch 28; iter: 200; batch classifier loss: 0.449509; batch adversarial loss: 0.678285\n",
      "epoch 29; iter: 0; batch classifier loss: 0.417025; batch adversarial loss: 0.662027\n",
      "epoch 29; iter: 200; batch classifier loss: 0.423729; batch adversarial loss: 0.642588\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477137; batch adversarial loss: 0.675551\n",
      "epoch 30; iter: 200; batch classifier loss: 0.351539; batch adversarial loss: 0.656509\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435542; batch adversarial loss: 0.667592\n",
      "epoch 31; iter: 200; batch classifier loss: 0.457967; batch adversarial loss: 0.692287\n",
      "epoch 32; iter: 0; batch classifier loss: 0.546178; batch adversarial loss: 0.643728\n",
      "epoch 32; iter: 200; batch classifier loss: 0.468294; batch adversarial loss: 0.645086\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445343; batch adversarial loss: 0.655285\n",
      "epoch 33; iter: 200; batch classifier loss: 0.426253; batch adversarial loss: 0.646142\n",
      "epoch 34; iter: 0; batch classifier loss: 0.512585; batch adversarial loss: 0.660318\n",
      "epoch 34; iter: 200; batch classifier loss: 0.410510; batch adversarial loss: 0.676222\n",
      "epoch 35; iter: 0; batch classifier loss: 0.449568; batch adversarial loss: 0.661472\n",
      "epoch 35; iter: 200; batch classifier loss: 0.456024; batch adversarial loss: 0.675442\n",
      "epoch 36; iter: 0; batch classifier loss: 0.404469; batch adversarial loss: 0.667367\n",
      "epoch 36; iter: 200; batch classifier loss: 0.458694; batch adversarial loss: 0.623283\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423272; batch adversarial loss: 0.634813\n",
      "epoch 37; iter: 200; batch classifier loss: 0.403960; batch adversarial loss: 0.636510\n",
      "epoch 38; iter: 0; batch classifier loss: 0.523361; batch adversarial loss: 0.629283\n",
      "epoch 38; iter: 200; batch classifier loss: 0.520177; batch adversarial loss: 0.666272\n",
      "epoch 39; iter: 0; batch classifier loss: 0.450680; batch adversarial loss: 0.663314\n",
      "epoch 39; iter: 200; batch classifier loss: 0.431086; batch adversarial loss: 0.667961\n",
      "epoch 40; iter: 0; batch classifier loss: 0.508581; batch adversarial loss: 0.646407\n",
      "epoch 40; iter: 200; batch classifier loss: 0.634723; batch adversarial loss: 0.671811\n",
      "epoch 41; iter: 0; batch classifier loss: 0.394707; batch adversarial loss: 0.701367\n",
      "epoch 41; iter: 200; batch classifier loss: 0.402755; batch adversarial loss: 0.637815\n",
      "epoch 42; iter: 0; batch classifier loss: 0.400773; batch adversarial loss: 0.634080\n",
      "epoch 42; iter: 200; batch classifier loss: 0.508934; batch adversarial loss: 0.657021\n",
      "epoch 43; iter: 0; batch classifier loss: 0.445791; batch adversarial loss: 0.651382\n",
      "epoch 43; iter: 200; batch classifier loss: 0.543519; batch adversarial loss: 0.663045\n",
      "epoch 44; iter: 0; batch classifier loss: 0.526194; batch adversarial loss: 0.697974\n",
      "epoch 44; iter: 200; batch classifier loss: 0.494333; batch adversarial loss: 0.647209\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448311; batch adversarial loss: 0.666059\n",
      "epoch 45; iter: 200; batch classifier loss: 0.393590; batch adversarial loss: 0.632447\n",
      "epoch 46; iter: 0; batch classifier loss: 0.520968; batch adversarial loss: 0.642423\n",
      "epoch 46; iter: 200; batch classifier loss: 0.439251; batch adversarial loss: 0.653946\n",
      "epoch 47; iter: 0; batch classifier loss: 0.476613; batch adversarial loss: 0.689496\n",
      "epoch 47; iter: 200; batch classifier loss: 0.539882; batch adversarial loss: 0.642557\n",
      "epoch 48; iter: 0; batch classifier loss: 0.478014; batch adversarial loss: 0.683503\n",
      "epoch 48; iter: 200; batch classifier loss: 0.531791; batch adversarial loss: 0.681507\n",
      "epoch 49; iter: 0; batch classifier loss: 0.455400; batch adversarial loss: 0.652100\n",
      "epoch 49; iter: 200; batch classifier loss: 0.395073; batch adversarial loss: 0.629758\n",
      "Adversarial Debiasing (FFNN) Performance:\n",
      "Accuracy : 0.8006\n",
      "Precision: 0.6959\n",
      "Recall   : 0.7637\n",
      "F1 Score : 0.7282\n",
      "\n",
      "Fairness Metrics (Adversarial Debiasing):\n",
      "Statistical Parity Difference : 0.2215\n",
      "Equal Opportunity Difference : 0.1276\n",
      "Disparate Impact Ratio       : 1.8576\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    demographic_parity_difference,\n",
    "    equalized_odds_difference,\n",
    "    selection_rate\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare AIF360 dataset again\n",
    "df_adv = pd.concat([X_scaled.reset_index(drop=True), y.reset_index(drop=True), protected.reset_index(drop=True)], axis=1)\n",
    "df_adv = df_adv.rename(columns={'race_binary': 'race', 'two_year_recid': 'target'})\n",
    "\n",
    "bld_full = BinaryLabelDataset(\n",
    "    df=df_adv,\n",
    "    label_names=[\"target\"],\n",
    "    protected_attribute_names=[\"race\"],\n",
    "    favorable_label=0,\n",
    "    unfavorable_label=1\n",
    ")\n",
    "\n",
    "train_bld_adv, test_bld_adv = bld_full.split([0.7], shuffle=True)\n",
    "\n",
    "# Adversarial Debiasing model\n",
    "sess = tf.Session()\n",
    "adv_debiasor = AdversarialDebiasing(\n",
    "    privileged_groups=[{\"race\": 0}],\n",
    "    unprivileged_groups=[{\"race\": 1}],\n",
    "    scope_name='adv_debiasing_ffnn',\n",
    "    sess=sess,\n",
    "    num_epochs=50,\n",
    "    batch_size=128,\n",
    "    debias=True\n",
    ")\n",
    "\n",
    "adv_debiasor.fit(train_bld_adv)\n",
    "\n",
    "# Predict on test set\n",
    "pred_bld_adv = adv_debiasor.predict(test_bld_adv)\n",
    "\n",
    "# Convert predictions to NumPy\n",
    "y_true = test_bld_adv.labels.ravel()\n",
    "y_pred = pred_bld_adv.labels.ravel()\n",
    "prot_attr = test_bld_adv.protected_attributes.ravel()\n",
    "\n",
    "# Evaluate Performance\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "print(\"Adversarial Debiasing (FFNN) Performance:\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# Fairness metrics\n",
    "fair_metrics_adv = MetricFrame(\n",
    "    metrics={\n",
    "        \"accuracy\": accuracy_score,\n",
    "        \"precision\": precision_score,\n",
    "        \"recall\": recall_score,\n",
    "        \"f1\": f1_score,\n",
    "        \"selection_rate\": selection_rate\n",
    "    },\n",
    "    y_true=y_true,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=prot_attr\n",
    ")\n",
    "\n",
    "spd = demographic_parity_difference(y_true, y_pred, sensitive_features=prot_attr)\n",
    "eod = equalized_odds_difference(y_true, y_pred, sensitive_features=prot_attr)\n",
    "di_ratio = fair_metrics_adv.by_group['selection_rate'].max() / fair_metrics_adv.by_group['selection_rate'].min()\n",
    "\n",
    "print(\"\\nFairness Metrics (Adversarial Debiasing):\")\n",
    "print(f\"Statistical Parity Difference : {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference : {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio       : {di_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1739cfce-2025-49ad-b3c5-98ca168dd01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equalized Odds Postprocessing (FFNN) Performance:\n",
      "Accuracy : 0.7433\n",
      "Precision: 0.6101\n",
      "Recall   : 0.7227\n",
      "F1 Score : 0.6617\n",
      "\n",
      "Fairness Metrics (Equalized Odds Postprocessing):\n",
      "Statistical Parity Difference : 0.0863\n",
      "Equal Opportunity Difference : 0.0059\n",
      "Disparate Impact Ratio       : 1.2372\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    demographic_parity_difference,\n",
    "    equalized_odds_difference,\n",
    "    selection_rate\n",
    ")\n",
    "\n",
    "# Recreate original test dataset from FFNN output\n",
    "df_eqodds = pd.concat([\n",
    "    pd.DataFrame(X_test_tensor.numpy(), columns=X_train.columns).reset_index(drop=True),\n",
    "    pd.Series(y_test.values, name='target').reset_index(drop=True),\n",
    "    pd.Series(prot_test.values, name='race').reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "test_bld_eq = BinaryLabelDataset(\n",
    "    df=df_eqodds,\n",
    "    label_names=[\"target\"],\n",
    "    protected_attribute_names=[\"race\"],\n",
    "    favorable_label=0,\n",
    "    unfavorable_label=1\n",
    ")\n",
    "\n",
    "# Create predicted label dataset (FFNN baseline)\n",
    "pred_bld_eq = test_bld_eq.copy()\n",
    "pred_bld_eq.labels = y_pred.reshape(-1, 1)\n",
    "\n",
    "# Apply Equalized Odds Postprocessing\n",
    "eq_odds = EqOddsPostprocessing(\n",
    "    privileged_groups=[{\"race\": 0}],\n",
    "    unprivileged_groups=[{\"race\": 1}],\n",
    "    seed=42\n",
    ")\n",
    "eq_odds = eq_odds.fit(test_bld_eq, pred_bld_eq)\n",
    "pred_eqodds = eq_odds.predict(pred_bld_eq)\n",
    "\n",
    "# Convert back to NumPy\n",
    "y_eq = pred_eqodds.labels.ravel()\n",
    "prot_attr = test_bld_eq.protected_attributes.ravel()\n",
    "y_true = test_bld_eq.labels.ravel()\n",
    "\n",
    "# Evaluate Performance\n",
    "acc = accuracy_score(y_true, y_eq)\n",
    "prec = precision_score(y_true, y_eq, zero_division=0)\n",
    "rec = recall_score(y_true, y_eq, zero_division=0)\n",
    "f1 = f1_score(y_true, y_eq, zero_division=0)\n",
    "\n",
    "print(\"Equalized Odds Postprocessing (FFNN) Performance:\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# Fairness Metrics\n",
    "fair_metrics_eq = MetricFrame(\n",
    "    metrics={\n",
    "        \"accuracy\": accuracy_score,\n",
    "        \"precision\": precision_score,\n",
    "        \"recall\": recall_score,\n",
    "        \"f1\": f1_score,\n",
    "        \"selection_rate\": selection_rate\n",
    "    },\n",
    "    y_true=y_true,\n",
    "    y_pred=y_eq,\n",
    "    sensitive_features=prot_attr\n",
    ")\n",
    "\n",
    "spd = demographic_parity_difference(y_true, y_eq, sensitive_features=prot_attr)\n",
    "eod = equalized_odds_difference(y_true, y_eq, sensitive_features=prot_attr)\n",
    "di_ratio = fair_metrics_eq.by_group['selection_rate'].max() / fair_metrics_eq.by_group['selection_rate'].min()\n",
    "\n",
    "print(\"\\nFairness Metrics (Equalized Odds Postprocessing):\")\n",
    "print(f\"Statistical Parity Difference : {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference : {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio       : {di_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca6f84-fb17-446f-b8de-5e1e33dc7373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-env]",
   "language": "python",
   "name": "conda-env-tf-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
