{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63084476-1a63-42bd-9001-d4c3cf3fb61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub pandas scikit-learn fairlearn aif360 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09aaee54-b0cc-43cc-b44b-adcca3b9a79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'kredit': [1 0]\n",
      "\n",
      "Logistic Regression Performance Metrics:\n",
      "Accuracy : 0.7833\n",
      "Precision: 0.8033\n",
      "Recall   : 0.9143\n",
      "F1 Score : 0.8552\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Arhamsoft\\Desktop\\Talha Talib Thesis\\german_credit_data.csv\")\n",
    "\n",
    "# Drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Show current target values\n",
    "print(\"Unique values in 'kredit':\", df['kredit'].unique())\n",
    "\n",
    "# Target and features\n",
    "y = df['kredit']  # Already binary: 0 = Good, 1 = Bad\n",
    "X = df.drop(columns=['kredit'])\n",
    "\n",
    "# Encode categorical features\n",
    "X_encoded = X.copy()\n",
    "for col in X_encoded.select_dtypes(include='object').columns:\n",
    "    X_encoded[col] = LabelEncoder().fit_transform(X_encoded[col])\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=2000, solver='saga')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Output results\n",
    "print(\"\\nLogistic Regression Performance Metrics:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6d972fc-4850-4036-bfa3-40250fe56289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reweighed Logistic Regression Performance:\n",
      "Accuracy : 0.7233\n",
      "Precision: 0.7230\n",
      "Recall   : 0.9953\n",
      "F1 Score : 0.8376\n",
      "\n",
      "Fairness Metrics (Reweighing):\n",
      "Statistical Parity Difference : 0.0148\n",
      "Equal Opportunity Difference : 0.0051\n",
      "Disparate Impact Ratio       : 1.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Derive gender from 'famges': 0 = female, 1 = male\n",
    "df['sex_binary'] = df['famges'].apply(lambda x: 0 if x == 4 else 1)\n",
    "\n",
    "# 2. Recombine features and target with gender\n",
    "full_data = pd.concat([X_encoded, y.rename('target'), df['sex_binary']], axis=1)\n",
    "\n",
    "# 3. Create BinaryLabelDataset for AIF360\n",
    "bld = BinaryLabelDataset(\n",
    "    df=full_data,\n",
    "    label_names=['target'],\n",
    "    protected_attribute_names=['sex_binary'],\n",
    "    favorable_label=1,  # 1 = good\n",
    "    unfavorable_label=0\n",
    ")\n",
    "\n",
    "# 4. Split into train/test sets\n",
    "train_bld, test_bld = bld.split([0.7], shuffle=True)\n",
    "\n",
    "# 5. Apply reweighing\n",
    "rw = Reweighing(\n",
    "    privileged_groups=[{'sex_binary': 1}],\n",
    "    unprivileged_groups=[{'sex_binary': 0}]\n",
    ")\n",
    "train_rw_bld = rw.fit_transform(train_bld)\n",
    "\n",
    "# 6. Prepare inputs\n",
    "X_train_rw = train_rw_bld.features\n",
    "y_train_rw = train_rw_bld.labels.ravel()\n",
    "w_train_rw = train_rw_bld.instance_weights\n",
    "\n",
    "X_test_rw = test_bld.features\n",
    "y_test_rw = test_bld.labels.ravel()\n",
    "\n",
    "# 7. Train weighted logistic regression\n",
    "model_rw = LogisticRegression(max_iter=2000, solver='saga')\n",
    "model_rw.fit(X_train_rw, y_train_rw, sample_weight=w_train_rw)\n",
    "\n",
    "# 8. Predict\n",
    "y_pred_rw = model_rw.predict(X_test_rw)\n",
    "\n",
    "# 9. Performance metrics\n",
    "acc = accuracy_score(y_test_rw, y_pred_rw)\n",
    "prec = precision_score(y_test_rw, y_pred_rw)\n",
    "rec = recall_score(y_test_rw, y_pred_rw)\n",
    "f1 = f1_score(y_test_rw, y_pred_rw)\n",
    "\n",
    "print(\"Reweighed Logistic Regression Performance:\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# 10. Fairness metrics\n",
    "pred_bld_rw = test_bld.copy()\n",
    "pred_bld_rw.labels = y_pred_rw.reshape(-1, 1)\n",
    "\n",
    "metric_rw = ClassificationMetric(\n",
    "    test_bld,\n",
    "    pred_bld_rw,\n",
    "    unprivileged_groups=[{'sex_binary': 0}],\n",
    "    privileged_groups=[{'sex_binary': 1}]\n",
    ")\n",
    "\n",
    "spd = metric_rw.statistical_parity_difference()\n",
    "eod = metric_rw.equal_opportunity_difference()\n",
    "dir_ = metric_rw.disparate_impact()\n",
    "\n",
    "print(\"\\nFairness Metrics (Reweighing):\")\n",
    "print(f\"Statistical Parity Difference : {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference : {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio       : {dir_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "841c82e5-b50d-45f2-8ab6-2899f4102756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\AppData\\Local\\Temp\\ipykernel_22576\\3674220304.py:9: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\AppData\\Local\\Temp\\ipykernel_22576\\3674220304.py:9: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:164: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:164: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 117.971664; batch adversarial loss: 0.749353\n",
      "epoch 1; iter: 0; batch classifier loss: 61.493839; batch adversarial loss: 0.926392\n",
      "epoch 2; iter: 0; batch classifier loss: 71.515488; batch adversarial loss: 0.910685\n",
      "epoch 3; iter: 0; batch classifier loss: 86.767815; batch adversarial loss: 0.921624\n",
      "epoch 4; iter: 0; batch classifier loss: 39.154564; batch adversarial loss: 0.929379\n",
      "epoch 5; iter: 0; batch classifier loss: 60.244118; batch adversarial loss: 0.881697\n",
      "epoch 6; iter: 0; batch classifier loss: 64.902222; batch adversarial loss: 0.801165\n",
      "epoch 7; iter: 0; batch classifier loss: 47.376999; batch adversarial loss: 0.827476\n",
      "epoch 8; iter: 0; batch classifier loss: 41.744339; batch adversarial loss: 0.761355\n",
      "epoch 9; iter: 0; batch classifier loss: 60.058620; batch adversarial loss: 0.859334\n",
      "epoch 10; iter: 0; batch classifier loss: 49.361801; batch adversarial loss: 0.859159\n",
      "epoch 11; iter: 0; batch classifier loss: 32.999069; batch adversarial loss: 0.821737\n",
      "epoch 12; iter: 0; batch classifier loss: 43.618858; batch adversarial loss: 0.872172\n",
      "epoch 13; iter: 0; batch classifier loss: 51.039459; batch adversarial loss: 0.849191\n",
      "epoch 14; iter: 0; batch classifier loss: 57.675625; batch adversarial loss: 0.730638\n",
      "epoch 15; iter: 0; batch classifier loss: 36.839825; batch adversarial loss: 0.859992\n",
      "epoch 16; iter: 0; batch classifier loss: 47.815624; batch adversarial loss: 0.861588\n",
      "epoch 17; iter: 0; batch classifier loss: 55.406296; batch adversarial loss: 0.858046\n",
      "epoch 18; iter: 0; batch classifier loss: 40.099232; batch adversarial loss: 0.870844\n",
      "epoch 19; iter: 0; batch classifier loss: 51.523190; batch adversarial loss: 0.819088\n",
      "epoch 20; iter: 0; batch classifier loss: 53.077976; batch adversarial loss: 0.725177\n",
      "epoch 21; iter: 0; batch classifier loss: 29.459431; batch adversarial loss: 0.831780\n",
      "epoch 22; iter: 0; batch classifier loss: 31.370480; batch adversarial loss: 0.855617\n",
      "epoch 23; iter: 0; batch classifier loss: 42.788490; batch adversarial loss: 0.817796\n",
      "epoch 24; iter: 0; batch classifier loss: 38.820679; batch adversarial loss: 0.839992\n",
      "epoch 25; iter: 0; batch classifier loss: 29.489864; batch adversarial loss: 0.838438\n",
      "epoch 26; iter: 0; batch classifier loss: 20.221180; batch adversarial loss: 0.759693\n",
      "epoch 27; iter: 0; batch classifier loss: 22.704563; batch adversarial loss: 0.813930\n",
      "epoch 28; iter: 0; batch classifier loss: 30.998882; batch adversarial loss: 0.798056\n",
      "epoch 29; iter: 0; batch classifier loss: 23.463608; batch adversarial loss: 0.766698\n",
      "epoch 30; iter: 0; batch classifier loss: 21.869793; batch adversarial loss: 0.765575\n",
      "epoch 31; iter: 0; batch classifier loss: 29.801872; batch adversarial loss: 0.797381\n",
      "epoch 32; iter: 0; batch classifier loss: 30.819412; batch adversarial loss: 0.811663\n",
      "epoch 33; iter: 0; batch classifier loss: 33.583641; batch adversarial loss: 0.799060\n",
      "epoch 34; iter: 0; batch classifier loss: 22.686855; batch adversarial loss: 0.802746\n",
      "epoch 35; iter: 0; batch classifier loss: 31.972769; batch adversarial loss: 0.766771\n",
      "epoch 36; iter: 0; batch classifier loss: 19.190287; batch adversarial loss: 0.810792\n",
      "epoch 37; iter: 0; batch classifier loss: 21.610758; batch adversarial loss: 0.741402\n",
      "epoch 38; iter: 0; batch classifier loss: 28.960442; batch adversarial loss: 0.748522\n",
      "epoch 39; iter: 0; batch classifier loss: 22.766254; batch adversarial loss: 0.722652\n",
      "epoch 40; iter: 0; batch classifier loss: 31.078344; batch adversarial loss: 0.804173\n",
      "epoch 41; iter: 0; batch classifier loss: 18.466278; batch adversarial loss: 0.742478\n",
      "epoch 42; iter: 0; batch classifier loss: 16.816376; batch adversarial loss: 0.788034\n",
      "epoch 43; iter: 0; batch classifier loss: 16.122189; batch adversarial loss: 0.740459\n",
      "epoch 44; iter: 0; batch classifier loss: 9.442558; batch adversarial loss: 0.789747\n",
      "epoch 45; iter: 0; batch classifier loss: 16.189323; batch adversarial loss: 0.794062\n",
      "epoch 46; iter: 0; batch classifier loss: 21.062183; batch adversarial loss: 0.740294\n",
      "epoch 47; iter: 0; batch classifier loss: 16.743273; batch adversarial loss: 0.744169\n",
      "epoch 48; iter: 0; batch classifier loss: 12.191017; batch adversarial loss: 0.781240\n",
      "epoch 49; iter: 0; batch classifier loss: 12.973812; batch adversarial loss: 0.718665\n",
      "Adversarial Debiasing Logistic Regression Performance:\n",
      "Accuracy : 0.6767\n",
      "Precision: 0.6767\n",
      "Recall   : 1.0000\n",
      "F1 Score : 0.8072\n",
      "\n",
      "Fairness Metrics (Adversarial Debiasing):\n",
      "Statistical Parity Difference : 0.0000\n",
      "Equal Opportunity Difference : 0.0000\n",
      "Disparate Impact Ratio       : 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Disable eager execution\n",
    "tf.disable_eager_execution()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Use 'famges' as gender proxy (already known)\n",
    "df['sex_binary'] = df['famges'].map({1: 1, 2: 0, 3: 1, 4: 0})  # 1 = male, 0 = female\n",
    "\n",
    "# Merge features with target and protected attribute\n",
    "X_encoded['sex_binary'] = df['sex_binary'].values\n",
    "full_data = pd.concat([X_encoded, y.rename(\"target\")], axis=1)\n",
    "\n",
    "# Construct BinaryLabelDataset\n",
    "bld = BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=full_data,\n",
    "    label_names=[\"target\"],\n",
    "    protected_attribute_names=[\"sex_binary\"]\n",
    ")\n",
    "\n",
    "# Train/test split using AIF360\n",
    "train_bld, test_bld = bld.split([0.7], shuffle=True)\n",
    "\n",
    "# Train model\n",
    "adv = AdversarialDebiasing(\n",
    "    privileged_groups=[{'sex_binary': 1}],\n",
    "    unprivileged_groups=[{'sex_binary': 0}],\n",
    "    scope_name='adv_debiasing',\n",
    "    sess=sess,\n",
    "    num_epochs=50\n",
    ")\n",
    "adv.fit(train_bld)\n",
    "\n",
    "# Predict\n",
    "pred_bld = adv.predict(test_bld)\n",
    "\n",
    "# Get labels\n",
    "y_pred = pred_bld.labels.ravel()\n",
    "y_true = test_bld.labels.ravel()\n",
    "\n",
    "# Performance\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"Adversarial Debiasing Logistic Regression Performance:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# Fairness Metrics\n",
    "metrics = ClassificationMetric(\n",
    "    test_bld,\n",
    "    pred_bld,\n",
    "    privileged_groups=[{'sex_binary': 1}],\n",
    "    unprivileged_groups=[{'sex_binary': 0}]\n",
    ")\n",
    "spd = metrics.statistical_parity_difference()\n",
    "eod = metrics.equal_opportunity_difference()\n",
    "dir_ratio = metrics.disparate_impact()\n",
    "\n",
    "print(\"\\nFairness Metrics (Adversarial Debiasing):\")\n",
    "print(f\"Statistical Parity Difference : {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference : {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio       : {dir_ratio:.4f}\")\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03973f3f-5418-407c-a083-7ff7b4b353cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equalized Odds Postprocessing Logistic Regression Performance:\n",
      "Accuracy : 0.7000\n",
      "Precision: 0.7339\n",
      "Recall   : 0.8593\n",
      "F1 Score : 0.7917\n",
      "\n",
      "Fairness Metrics (Equalized Odds Postprocessing):\n",
      "Statistical Parity Difference : 0.0081\n",
      "Equal Opportunity Difference : 0.0089\n",
      "Disparate Impact Ratio       : 1.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arhamsoft\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Reconstruct dataset\n",
    "X_encoded['sex_binary'] = df['sex_binary'].values\n",
    "full_data = pd.concat([X_encoded, y.rename(\"target\")], axis=1)\n",
    "\n",
    "bld = BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=full_data,\n",
    "    label_names=[\"target\"],\n",
    "    protected_attribute_names=[\"sex_binary\"]\n",
    ")\n",
    "\n",
    "train_bld, test_bld = bld.split([0.7], shuffle=True)\n",
    "\n",
    "# Train baseline model (logistic regression)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(train_bld.features, train_bld.labels.ravel())\n",
    "pred_probs = model.predict_proba(test_bld.features)[:, 1]\n",
    "pred_labels = (pred_probs >= 0.5).astype(int)\n",
    "\n",
    "# Wrap prediction into BinaryLabelDataset\n",
    "test_pred = test_bld.copy()\n",
    "test_pred.labels = pred_labels.reshape(-1, 1)\n",
    "\n",
    "# Equalized Odds Postprocessing\n",
    "eq_odds = EqOddsPostprocessing(\n",
    "    privileged_groups=[{'sex_binary': 1}],\n",
    "    unprivileged_groups=[{'sex_binary': 0}]\n",
    ")\n",
    "eq_odds = eq_odds.fit(test_bld, test_pred)\n",
    "eq_pred = eq_odds.predict(test_pred)\n",
    "\n",
    "# Extract predictions\n",
    "y_pred_eq = eq_pred.labels.ravel()\n",
    "y_true_eq = test_bld.labels.ravel()\n",
    "\n",
    "# Performance metrics\n",
    "accuracy = accuracy_score(y_true_eq, y_pred_eq)\n",
    "precision = precision_score(y_true_eq, y_pred_eq)\n",
    "recall = recall_score(y_true_eq, y_pred_eq)\n",
    "f1 = f1_score(y_true_eq, y_pred_eq)\n",
    "\n",
    "print(\"Equalized Odds Postprocessing Logistic Regression Performance:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# Fairness metrics\n",
    "metric = ClassificationMetric(\n",
    "    test_bld,\n",
    "    eq_pred,\n",
    "    privileged_groups=[{'sex_binary': 1}],\n",
    "    unprivileged_groups=[{'sex_binary': 0}]\n",
    ")\n",
    "spd = metric.statistical_parity_difference()\n",
    "eod = metric.equal_opportunity_difference()\n",
    "dir_ratio = metric.disparate_impact()\n",
    "\n",
    "print(\"\\nFairness Metrics (Equalized Odds Postprocessing):\")\n",
    "print(f\"Statistical Parity Difference : {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference : {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio       : {dir_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f196d955-5639-43ca-ac09-eada346a1a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-env]",
   "language": "python",
   "name": "conda-env-tf-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
