{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63084476-1a63-42bd-9001-d4c3cf3fb61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub pandas scikit-learn fairlearn aif360 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09aaee54-b0cc-43cc-b44b-adcca3b9a79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (60843, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arhamsoft\\AppData\\Local\\Temp\\ipykernel_29564\\4235935015.py:34: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['DateOfBirth'] = pd.to_datetime(df['DateOfBirth'], errors='coerce')\n",
      "C:\\Users\\Arhamsoft\\AppData\\Local\\Temp\\ipykernel_29564\\4235935015.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Screening_Date'] = pd.to_datetime(df['Screening_Date'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (34136, 16)\n",
      "y_train class balance:\n",
      " two_year_recid\n",
      "0    0.652625\n",
      "1    0.347375\n",
      "Name: proportion, dtype: float64\n",
      "Protected attribute (train):\n",
      " race_binary\n",
      "1    18949\n",
      "0    15187\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    demographic_parity_difference,\n",
    "    equalized_odds_difference,\n",
    "    selection_rate,\n",
    "    count\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Arhamsoft\\Desktop\\Talha Talib Thesis\\compas-scores-raw.csv\")\n",
    "print(\"Original shape:\", df.shape)\n",
    "\n",
    "# Filtering\n",
    "df = df[\n",
    "    (df['IsCompleted'] == 1) &\n",
    "    (df['ScoreText'].isin(['Low', 'Medium', 'High']))\n",
    "]\n",
    "\n",
    "# Target: 1 = reoffended (Medium or High), 0 = Low\n",
    "df['two_year_recid'] = df['ScoreText'].map({'Low': 0, 'Medium': 1, 'High': 1})\n",
    "\n",
    "# Keep only African-American and Caucasian\n",
    "df = df[df['Ethnic_Code_Text'].isin(['African-American', 'Caucasian'])]\n",
    "df['race_binary'] = df['Ethnic_Code_Text'].map({'Caucasian': 0, 'African-American': 1})\n",
    "df['sex_binary'] = df['Sex_Code_Text'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "# Derive age from DateOfBirth and Screening_Date\n",
    "df['DateOfBirth'] = pd.to_datetime(df['DateOfBirth'], errors='coerce')\n",
    "df['Screening_Date'] = pd.to_datetime(df['Screening_Date'], errors='coerce')\n",
    "df['age'] = (df['Screening_Date'] - df['DateOfBirth']).dt.days // 365\n",
    "\n",
    "# Drop rows with missing values in new fields\n",
    "df = df.dropna(subset=['age', 'LegalStatus', 'CustodyStatus', 'RecSupervisionLevel'])\n",
    "\n",
    "# Encode categorical features\n",
    "df = pd.get_dummies(df, columns=['LegalStatus', 'CustodyStatus', 'RecSupervisionLevel'], drop_first=True)\n",
    "\n",
    "# Select features\n",
    "features = ['sex_binary', 'age'] + [col for col in df.columns if col.startswith('LegalStatus_') or col.startswith('CustodyStatus_') or col.startswith('RecSupervisionLevel_')]\n",
    "X = df[features]\n",
    "y = df['two_year_recid']\n",
    "protected = df['race_binary']\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test, prot_train, prot_test = train_test_split(\n",
    "    X_scaled, y, protected, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Check outputs\n",
    "print(\"Final shape:\", X_train.shape)\n",
    "print(\"y_train class balance:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Protected attribute (train):\\n\", prot_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88f03909-e725-4a4e-b1b6-92f609b59999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Performance Metrics:\n",
      "Accuracy : 0.7994\n",
      "Precision: 0.6792\n",
      "Recall   : 0.8007\n",
      "F1 Score : 0.7349\n",
      "\n",
      "üìä Per-group Accuracy and Selection Rate:\n",
      "             accuracy  selection_rate   count\n",
      "race_binary                                  \n",
      "0            0.829735        0.260718  6578.0\n",
      "1            0.774618        0.530982  8053.0\n",
      "\n",
      "‚öñÔ∏è Fairness Metrics:\n",
      "Statistical Parity Difference  (SPD): 0.2703\n",
      "Equal Opportunity Difference  (EOD): 0.1759\n",
      "Disparate Impact Ratio (DIR)       : 2.0366\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# Fairness metrics\n",
    "metric_frame = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate, \"count\": count},\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=prot_test\n",
    ")\n",
    "\n",
    "print(\"\\nPer-group Accuracy and Selection Rate:\")\n",
    "print(metric_frame.by_group)\n",
    "\n",
    "# üìè Fairness differences\n",
    "spd = demographic_parity_difference(y_test, y_pred, sensitive_features=prot_test)\n",
    "eod = equalized_odds_difference(y_test, y_pred, sensitive_features=prot_test)\n",
    "sr = metric_frame.by_group[\"selection_rate\"]\n",
    "dir_ratio = sr[1] / sr[0] if sr[0] != 0 else float(\"inf\")\n",
    "\n",
    "print(\"\\n‚öñÔ∏è Fairness Metrics:\")\n",
    "print(f\"Statistical Parity Difference  (SPD): {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference  (EOD): {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio (DIR)       : {dir_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876b0093-fe03-4af6-a121-6699a6bfee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Reweighed Model Performance:\n",
      "Accuracy : 0.7994\n",
      "Precision: 0.6792\n",
      "Recall   : 0.8007\n",
      "F1 Score : 0.7349\n",
      "\n",
      "üìä Reweighed Group Metrics:\n",
      "             accuracy  selection_rate   count\n",
      "race_binary                                  \n",
      "0            0.829735        0.260718  6578.0\n",
      "1            0.774618        0.530982  8053.0\n",
      "\n",
      "‚öñÔ∏è Reweighed Fairness Metrics:\n",
      "Statistical Parity Difference  (SPD): 0.2703\n",
      "Equal Opportunity Difference  (EOD): 0.1759\n",
      "Disparate Impact Ratio (DIR)       : 2.0366\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    demographic_parity_difference,\n",
    "    equalized_odds_difference,\n",
    "    selection_rate,\n",
    "    count\n",
    ")\n",
    "\n",
    "# Step 1: Convert to AIF360 BinaryLabelDataset\n",
    "# Define privileged/unprivileged groups for race\n",
    "privileged_groups = [{'race_binary': 0}]\n",
    "unprivileged_groups = [{'race_binary': 1}]\n",
    "\n",
    "# Combine back into a single training DataFrame with labels and protected attributes\n",
    "train_df = X_train.copy()\n",
    "train_df['label'] = y_train.values\n",
    "train_df['race_binary'] = prot_train.values\n",
    "\n",
    "# Convert to AIF360 dataset\n",
    "train_bld = BinaryLabelDataset(\n",
    "    df=train_df,\n",
    "    label_names=['label'],\n",
    "    protected_attribute_names=['race_binary']\n",
    ")\n",
    "\n",
    "# Step 2: Apply Reweighing\n",
    "rw = Reweighing(\n",
    "    privileged_groups=privileged_groups,\n",
    "    unprivileged_groups=unprivileged_groups\n",
    ")\n",
    "rw.fit(train_bld)\n",
    "train_bld_rw = rw.transform(train_bld)\n",
    "\n",
    "# Extract features and labels\n",
    "X_train_rw = pd.DataFrame(train_bld_rw.features, columns=train_bld_rw.feature_names)\n",
    "# Drop race_binary so features match X_test\n",
    "X_train_rw = X_train_rw.drop(columns=[\"race_binary\"])\n",
    "\n",
    "y_train_rw = train_bld_rw.labels.ravel()\n",
    "sample_weights = train_bld_rw.instance_weights\n",
    "\n",
    "# Step 3: Train weighted Logistic Regression\n",
    "lr_rw_model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "lr_rw_model.fit(X_train_rw, y_train_rw, sample_weight=sample_weights)\n",
    "\n",
    "# Step 4: Predict on test set\n",
    "y_pred_rw = lr_rw_model.predict(X_test)\n",
    "\n",
    "# Performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_rw)\n",
    "precision = precision_score(y_test, y_pred_rw)\n",
    "recall = recall_score(y_test, y_pred_rw)\n",
    "f1 = f1_score(y_test, y_pred_rw)\n",
    "\n",
    "print(\"Reweighed Model Performance:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# Fairness evaluation\n",
    "metric_frame_rw = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate, \"count\": count},\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_rw,\n",
    "    sensitive_features=prot_test\n",
    ")\n",
    "\n",
    "print(\"\\nReweighed Group Metrics:\")\n",
    "print(metric_frame_rw.by_group)\n",
    "\n",
    "# Fairness Metrics\n",
    "spd = demographic_parity_difference(y_test, y_pred_rw, sensitive_features=prot_test)\n",
    "eod = equalized_odds_difference(y_test, y_pred_rw, sensitive_features=prot_test)\n",
    "sr = metric_frame_rw.by_group[\"selection_rate\"]\n",
    "dir_ratio = sr[1] / sr[0] if sr[0] != 0 else float(\"inf\")\n",
    "\n",
    "print(\"\\nReweighed Fairness Metrics:\")\n",
    "print(f\"Statistical Parity Difference  (SPD): {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference  (EOD): {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio (DIR)       : {dir_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33dddd95-e3d0-4553-b8ec-34641c67e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Equalized Odds Performance:\n",
      "Accuracy : 0.7667\n",
      "Precision: 0.6437\n",
      "Recall   : 0.7349\n",
      "F1 Score : 0.6863\n",
      "\n",
      "üìä Equalized Odds Group Metrics:\n",
      "             accuracy  selection_rate   count\n",
      "race_binary                                  \n",
      "0            0.776072        0.340833  6578.0\n",
      "1            0.758972        0.442071  8053.0\n",
      "\n",
      "‚öñÔ∏è Equalized Odds Fairness Metrics:\n",
      "Statistical Parity Difference  (SPD): 0.1012\n",
      "Equal Opportunity Difference  (EOD): 0.0130\n",
      "Disparate Impact Ratio (DIR)       : 1.2970\n"
     ]
    }
   ],
   "source": [
    "# Install Fairlearn if not done already\n",
    "!pip install fairlearn --quiet\n",
    "\n",
    "# Imports\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Step 1: Create a ThresholdOptimizer (Equalized Odds)\n",
    "eo = ThresholdOptimizer(\n",
    "    estimator=lr_model,  # your already trained Logistic Regression\n",
    "    constraints=\"equalized_odds\",\n",
    "    predict_method=\"predict_proba\",  # required for probabilistic predictions\n",
    "    prefit=True  # model is already trained\n",
    ")\n",
    "\n",
    "# Step 2: Fit the optimizer\n",
    "eo.fit(X_train, y_train, sensitive_features=prot_train)\n",
    "\n",
    "# Step 3: Predict using post-processed predictions\n",
    "y_pred_eo = eo.predict(X_test, sensitive_features=prot_test)\n",
    "\n",
    "# Performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_eo)\n",
    "precision = precision_score(y_test, y_pred_eo)\n",
    "recall = recall_score(y_test, y_pred_eo)\n",
    "f1 = f1_score(y_test, y_pred_eo)\n",
    "\n",
    "print(\"Equalized Odds Performance:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# Fairness metrics\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    demographic_parity_difference,\n",
    "    equalized_odds_difference,\n",
    "    selection_rate,\n",
    "    count\n",
    ")\n",
    "\n",
    "metric_frame_eo = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate, \"count\": count},\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_eo,\n",
    "    sensitive_features=prot_test\n",
    ")\n",
    "\n",
    "print(\"\\nEqualized Odds Group Metrics:\")\n",
    "print(metric_frame_eo.by_group)\n",
    "\n",
    "# Group fairness metrics\n",
    "spd = demographic_parity_difference(y_test, y_pred_eo, sensitive_features=prot_test)\n",
    "eod = equalized_odds_difference(y_test, y_pred_eo, sensitive_features=prot_test)\n",
    "sr = metric_frame_eo.by_group[\"selection_rate\"]\n",
    "dir_ratio = sr[1] / sr[0] if sr[0] != 0 else float(\"inf\")\n",
    "\n",
    "print(\"\\nEqualized Odds Fairness Metrics:\")\n",
    "print(f\"Statistical Parity Difference  (SPD): {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference  (EOD): {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio (DIR)       : {dir_ratio:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64466b18-0747-4326-82ce-4a55521964d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.671116; batch adversarial loss: 0.678775\n",
      "epoch 1; iter: 0; batch classifier loss: 0.614873; batch adversarial loss: 0.690508\n",
      "epoch 2; iter: 0; batch classifier loss: 0.622071; batch adversarial loss: 0.683565\n",
      "epoch 3; iter: 0; batch classifier loss: 0.686680; batch adversarial loss: 0.680954\n",
      "epoch 4; iter: 0; batch classifier loss: 0.656803; batch adversarial loss: 0.688287\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592808; batch adversarial loss: 0.658564\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581240; batch adversarial loss: 0.698688\n",
      "epoch 7; iter: 0; batch classifier loss: 0.602844; batch adversarial loss: 0.672319\n",
      "epoch 8; iter: 0; batch classifier loss: 0.607793; batch adversarial loss: 0.659699\n",
      "epoch 9; iter: 0; batch classifier loss: 0.568660; batch adversarial loss: 0.608240\n",
      "epoch 10; iter: 0; batch classifier loss: 0.669990; batch adversarial loss: 0.588737\n",
      "epoch 11; iter: 0; batch classifier loss: 0.600053; batch adversarial loss: 0.517476\n",
      "epoch 12; iter: 0; batch classifier loss: 0.662254; batch adversarial loss: 0.514782\n",
      "epoch 13; iter: 0; batch classifier loss: 0.599504; batch adversarial loss: 0.456740\n",
      "epoch 14; iter: 0; batch classifier loss: 0.684634; batch adversarial loss: 0.446544\n",
      "epoch 15; iter: 0; batch classifier loss: 0.649855; batch adversarial loss: 0.414954\n",
      "epoch 16; iter: 0; batch classifier loss: 0.572683; batch adversarial loss: 0.395786\n",
      "epoch 17; iter: 0; batch classifier loss: 0.617971; batch adversarial loss: 0.441489\n",
      "epoch 18; iter: 0; batch classifier loss: 0.629674; batch adversarial loss: 0.485573\n",
      "epoch 19; iter: 0; batch classifier loss: 0.659305; batch adversarial loss: 0.488069\n",
      "epoch 20; iter: 0; batch classifier loss: 0.604920; batch adversarial loss: 0.444113\n",
      "epoch 21; iter: 0; batch classifier loss: 0.603086; batch adversarial loss: 0.396135\n",
      "epoch 22; iter: 0; batch classifier loss: 0.573690; batch adversarial loss: 0.391158\n",
      "epoch 23; iter: 0; batch classifier loss: 0.656629; batch adversarial loss: 0.412948\n",
      "epoch 24; iter: 0; batch classifier loss: 0.649078; batch adversarial loss: 0.415659\n",
      "epoch 25; iter: 0; batch classifier loss: 0.640167; batch adversarial loss: 0.417804\n",
      "epoch 26; iter: 0; batch classifier loss: 0.613129; batch adversarial loss: 0.393278\n",
      "epoch 27; iter: 0; batch classifier loss: 0.606826; batch adversarial loss: 0.386493\n",
      "epoch 28; iter: 0; batch classifier loss: 0.657257; batch adversarial loss: 0.382755\n",
      "epoch 29; iter: 0; batch classifier loss: 0.655844; batch adversarial loss: 0.410158\n",
      "epoch 30; iter: 0; batch classifier loss: 0.605621; batch adversarial loss: 0.359155\n",
      "epoch 31; iter: 0; batch classifier loss: 0.630318; batch adversarial loss: 0.419147\n",
      "epoch 32; iter: 0; batch classifier loss: 0.649209; batch adversarial loss: 0.376998\n",
      "epoch 33; iter: 0; batch classifier loss: 0.648271; batch adversarial loss: 0.366832\n",
      "epoch 34; iter: 0; batch classifier loss: 0.645161; batch adversarial loss: 0.392839\n",
      "epoch 35; iter: 0; batch classifier loss: 0.652295; batch adversarial loss: 0.373680\n",
      "epoch 36; iter: 0; batch classifier loss: 0.558253; batch adversarial loss: 0.330806\n",
      "epoch 37; iter: 0; batch classifier loss: 0.618520; batch adversarial loss: 0.353972\n",
      "epoch 38; iter: 0; batch classifier loss: 0.632615; batch adversarial loss: 0.352867\n",
      "epoch 39; iter: 0; batch classifier loss: 0.662390; batch adversarial loss: 0.360005\n",
      "epoch 40; iter: 0; batch classifier loss: 0.606647; batch adversarial loss: 0.345650\n",
      "epoch 41; iter: 0; batch classifier loss: 0.598174; batch adversarial loss: 0.351564\n",
      "epoch 42; iter: 0; batch classifier loss: 0.647550; batch adversarial loss: 0.357183\n",
      "epoch 43; iter: 0; batch classifier loss: 0.617061; batch adversarial loss: 0.350918\n",
      "epoch 44; iter: 0; batch classifier loss: 0.613323; batch adversarial loss: 0.371667\n",
      "epoch 45; iter: 0; batch classifier loss: 0.656324; batch adversarial loss: 0.357473\n",
      "epoch 46; iter: 0; batch classifier loss: 0.637498; batch adversarial loss: 0.376690\n",
      "epoch 47; iter: 0; batch classifier loss: 0.609076; batch adversarial loss: 0.382030\n",
      "epoch 48; iter: 0; batch classifier loss: 0.661911; batch adversarial loss: 0.319905\n",
      "epoch 49; iter: 0; batch classifier loss: 0.574490; batch adversarial loss: 0.305866\n",
      "epoch 50; iter: 0; batch classifier loss: 0.575164; batch adversarial loss: 0.373103\n",
      "epoch 51; iter: 0; batch classifier loss: 0.596688; batch adversarial loss: 0.291249\n",
      "epoch 52; iter: 0; batch classifier loss: 0.587198; batch adversarial loss: 0.354797\n",
      "epoch 53; iter: 0; batch classifier loss: 0.677021; batch adversarial loss: 0.360963\n",
      "epoch 54; iter: 0; batch classifier loss: 0.620371; batch adversarial loss: 0.348684\n",
      "epoch 55; iter: 0; batch classifier loss: 0.633703; batch adversarial loss: 0.354133\n",
      "epoch 56; iter: 0; batch classifier loss: 0.630494; batch adversarial loss: 0.440293\n",
      "epoch 57; iter: 0; batch classifier loss: 0.581898; batch adversarial loss: 0.390484\n",
      "epoch 58; iter: 0; batch classifier loss: 0.628764; batch adversarial loss: 0.431205\n",
      "epoch 59; iter: 0; batch classifier loss: 0.592037; batch adversarial loss: 0.481866\n",
      "epoch 60; iter: 0; batch classifier loss: 0.646457; batch adversarial loss: 0.463044\n",
      "epoch 61; iter: 0; batch classifier loss: 0.663087; batch adversarial loss: 0.488826\n",
      "epoch 62; iter: 0; batch classifier loss: 0.639620; batch adversarial loss: 0.427719\n",
      "epoch 63; iter: 0; batch classifier loss: 0.704926; batch adversarial loss: 0.604353\n",
      "epoch 64; iter: 0; batch classifier loss: 0.642434; batch adversarial loss: 0.748108\n",
      "epoch 65; iter: 0; batch classifier loss: 0.640920; batch adversarial loss: 0.787509\n",
      "epoch 66; iter: 0; batch classifier loss: 0.660749; batch adversarial loss: 0.799492\n",
      "epoch 67; iter: 0; batch classifier loss: 0.624502; batch adversarial loss: 0.800721\n",
      "epoch 68; iter: 0; batch classifier loss: 0.674490; batch adversarial loss: 0.795269\n",
      "epoch 69; iter: 0; batch classifier loss: 0.653679; batch adversarial loss: 0.786273\n",
      "epoch 70; iter: 0; batch classifier loss: 0.791536; batch adversarial loss: 0.782527\n",
      "epoch 71; iter: 0; batch classifier loss: 0.702430; batch adversarial loss: 0.898904\n",
      "epoch 72; iter: 0; batch classifier loss: 0.684865; batch adversarial loss: 0.832097\n",
      "epoch 73; iter: 0; batch classifier loss: 0.677724; batch adversarial loss: 0.742830\n",
      "epoch 74; iter: 0; batch classifier loss: 0.644264; batch adversarial loss: 0.727561\n",
      "epoch 75; iter: 0; batch classifier loss: 0.655309; batch adversarial loss: 0.740870\n",
      "epoch 76; iter: 0; batch classifier loss: 0.665873; batch adversarial loss: 0.691361\n",
      "epoch 77; iter: 0; batch classifier loss: 0.670419; batch adversarial loss: 0.619413\n",
      "epoch 78; iter: 0; batch classifier loss: 0.686776; batch adversarial loss: 0.575719\n",
      "epoch 79; iter: 0; batch classifier loss: 0.586116; batch adversarial loss: 0.526327\n",
      "epoch 80; iter: 0; batch classifier loss: 0.628525; batch adversarial loss: 0.529145\n",
      "epoch 81; iter: 0; batch classifier loss: 0.638080; batch adversarial loss: 0.433206\n",
      "epoch 82; iter: 0; batch classifier loss: 0.653214; batch adversarial loss: 0.429857\n",
      "epoch 83; iter: 0; batch classifier loss: 0.655475; batch adversarial loss: 0.302899\n",
      "epoch 84; iter: 0; batch classifier loss: 0.640858; batch adversarial loss: 0.290362\n",
      "epoch 85; iter: 0; batch classifier loss: 0.648453; batch adversarial loss: 0.309153\n",
      "epoch 86; iter: 0; batch classifier loss: 0.688470; batch adversarial loss: 0.298124\n",
      "epoch 87; iter: 0; batch classifier loss: 0.596416; batch adversarial loss: 0.317268\n",
      "epoch 88; iter: 0; batch classifier loss: 0.660970; batch adversarial loss: 0.337684\n",
      "epoch 89; iter: 0; batch classifier loss: 0.634343; batch adversarial loss: 0.306567\n",
      "epoch 90; iter: 0; batch classifier loss: 0.630556; batch adversarial loss: 0.294504\n",
      "epoch 91; iter: 0; batch classifier loss: 0.612243; batch adversarial loss: 0.317196\n",
      "epoch 92; iter: 0; batch classifier loss: 0.599911; batch adversarial loss: 0.316881\n",
      "epoch 93; iter: 0; batch classifier loss: 0.634581; batch adversarial loss: 0.371053\n",
      "epoch 94; iter: 0; batch classifier loss: 0.641847; batch adversarial loss: 0.384343\n",
      "epoch 95; iter: 0; batch classifier loss: 0.560648; batch adversarial loss: 0.371626\n",
      "epoch 96; iter: 0; batch classifier loss: 0.641600; batch adversarial loss: 0.369942\n",
      "epoch 97; iter: 0; batch classifier loss: 0.638324; batch adversarial loss: 0.355816\n",
      "epoch 98; iter: 0; batch classifier loss: 0.571082; batch adversarial loss: 0.359495\n",
      "epoch 99; iter: 0; batch classifier loss: 0.657155; batch adversarial loss: 0.315086\n",
      "\n",
      "üîç Prediction distribution:\n",
      "(array([0., 1.]), array([3453,   45]))\n",
      "\n",
      "üìà Adversarial Debiasing Performance:\n",
      "Accuracy : 0.6567\n",
      "Precision: 0.4000\n",
      "Recall   : 0.0151\n",
      "F1 Score : 0.0291\n",
      "\n",
      "‚öñÔ∏è Adversarial Debiasing Fairness Metrics:\n",
      "Statistical Parity Difference  (SPD): -0.0236\n",
      "Equal Opportunity Difference  (EOD): -0.0243\n",
      "Disparate Impact Ratio (DIR)       : 0.9764\n"
     ]
    }
   ],
   "source": [
    "# Adversarial Debiasing - Improved Fairness-Aware Training\n",
    "\n",
    "# --- Reset TensorFlow graph ---\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# --- OPTIONAL: Expand feature set if needed (already scaled) ---\n",
    "# If you previously filtered features to just 3, now add more if available\n",
    "# Example:\n",
    "# features = ['RawScore', 'DecileScore', 'sex_binary', 'CustodyStatus', ...]\n",
    "\n",
    "# --- Rebuild combined dataframes ---\n",
    "train_df = pd.concat([X_train, y_train.rename(\"two_year_recid\"), prot_train.rename(\"race_binary\")], axis=1).dropna()\n",
    "test_df  = pd.concat([X_test, y_test.rename(\"two_year_recid\"), prot_test.rename(\"race_binary\")], axis=1).dropna()\n",
    "\n",
    "# --- Convert to AIF360 BinaryLabelDataset format ---\n",
    "train_bld = BinaryLabelDataset(\n",
    "    favorable_label=0,\n",
    "    unfavorable_label=1,\n",
    "    df=train_df,\n",
    "    label_names=[\"two_year_recid\"],\n",
    "    protected_attribute_names=[\"race_binary\"]\n",
    ")\n",
    "\n",
    "test_bld = BinaryLabelDataset(\n",
    "    favorable_label=0,\n",
    "    unfavorable_label=1,\n",
    "    df=test_df,\n",
    "    label_names=[\"two_year_recid\"],\n",
    "    protected_attribute_names=[\"race_binary\"]\n",
    ")\n",
    "\n",
    "# --- Train Adversarial Debiasing model ---\n",
    "adv_debias = AdversarialDebiasing(\n",
    "    privileged_groups=[{'race_binary': 0}],\n",
    "    unprivileged_groups=[{'race_binary': 1}],\n",
    "    scope_name='adv_debiasing_classifier',\n",
    "    sess=sess,\n",
    "    debias=True,\n",
    "    num_epochs=100,\n",
    "    batch_size=128,\n",
    "    adversary_loss_weight=0.001   \n",
    ")\n",
    "adv_debias.fit(train_bld)\n",
    "\n",
    "# --- Predict on test set ---\n",
    "pred_bld = adv_debias.predict(test_bld)\n",
    "\n",
    "# --- Extract values for evaluation ---\n",
    "y_pred_adv = pred_bld.labels.ravel()\n",
    "y_true_adv = test_bld.labels.ravel()\n",
    "prot_attr_adv = test_bld.protected_attributes.ravel()\n",
    "\n",
    "# --- Check prediction distribution (for debugging) ---\n",
    "import numpy as np\n",
    "print(\"\\nPrediction distribution:\")\n",
    "print(np.unique(y_pred_adv, return_counts=True))\n",
    "\n",
    "# --- Evaluate Performance Metrics ---\n",
    "accuracy = accuracy_score(y_true_adv, y_pred_adv)\n",
    "precision = precision_score(y_true_adv, y_pred_adv, zero_division=0)\n",
    "recall = recall_score(y_true_adv, y_pred_adv, zero_division=0)\n",
    "f1 = f1_score(y_true_adv, y_pred_adv, zero_division=0)\n",
    "\n",
    "print(\"\\nAdversarial Debiasing Performance:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# --- Evaluate Fairness Metrics ---\n",
    "metric_adv = ClassificationMetric(\n",
    "    test_bld,\n",
    "    pred_bld,\n",
    "    unprivileged_groups=[{'race_binary': 1}],\n",
    "    privileged_groups=[{'race_binary': 0}]\n",
    ")\n",
    "\n",
    "spd = metric_adv.statistical_parity_difference()\n",
    "eod = metric_adv.equal_opportunity_difference()\n",
    "dir_ratio = metric_adv.disparate_impact()\n",
    "\n",
    "print(\"\\n Adversarial Debiasing Fairness Metrics:\")\n",
    "print(f\"Statistical Parity Difference  (SPD): {spd:.4f}\")\n",
    "print(f\"Equal Opportunity Difference  (EOD): {eod:.4f}\")\n",
    "print(f\"Disparate Impact Ratio (DIR)       : {dir_ratio:.4f}\")\n",
    "\n",
    "# --- Close TF session ---\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d972fc-4850-4036-bfa3-40250fe56289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-env]",
   "language": "python",
   "name": "conda-env-tf-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
